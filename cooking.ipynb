{
  "cells": [
    {
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom collections import defaultdict\nimport re\n\nimport os\nprint(os.listdir(\"../input\"))\n\n\nimport nltk\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.tokenize import word_tokenize\n\nfrom sklearn.preprocessing import LabelEncoder, FunctionTransformer\nfrom sklearn.pipeline import make_pipeline, make_union\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import cross_val_score, train_test_split\nfrom sklearn.externals import joblib\n\n#nn\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout\n\n#svm\nfrom  sklearn.svm import SVC\nfrom sklearn.multiclass import OneVsRestClassifier\n\n\n# Any results you write to the current directory are saved as output.",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "0fefc1914e8e5ccdfba739b6f711e86b7db4c5d7"
      },
      "cell_type": "markdown",
      "source": "**Opening files containing the dataset**"
    },
    {
      "metadata": {
        "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
        "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
        "trusted": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "df = pd.read_json(\"../input/train.json\")\ntest_df = pd.read_json(\"../input/test.json\")",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "91e23af70a77a6a6b905f57babf90a55a1c034aa"
      },
      "cell_type": "markdown",
      "source": "**Getting rid of all recipes that consist of just one ingredient**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "f2e3db92b91128a894dd7cca2c1da40dfdf619e8",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "df['num_ingredients'] = df['ingredients'].apply(lambda x: len(x))\ndf = df[df['num_ingredients'] > 1]",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "1dbdde9ef980d30198dd18f3fdbd90353192186c"
      },
      "cell_type": "markdown",
      "source": "**Preprocessing: **\n* lowering all words\n* deleting words with weird characters\n* lemmatization -\n* droping words shorter than 2 characters"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2857134890c1537a03fc44bbd17d966bc308d555",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "lemmatizer = WordNetLemmatizer()\ndef preprocess(ingredients):\n    ingredients_text = ' '.join(ingredients)\n    ingredients_text = ingredients_text.lower()\n    ingredients_text = ingredients_text.replace('-', ' ')\n    ingredients\n    words = []\n    for word in ingredients_text.split():\n        if re.findall('[0-9]', word): \n            continue\n        if '’' in word: \n            continue\n        if '®' in word:\n            continue\n        if ',' in word:\n            continue\n        if '.' in word:\n            continue\n        if '(' in word:\n            continue\n        if ')' in word:\n            continue\n        if '™' in word:\n            continue\n        \n        word = lemmatizer.lemmatize(word)\n        if len(word) > 2:\n            words.append(word)\n    return ' '.join(words)\n\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "a1a6da28fc3b207975705e230fb10ecd4ca7fc90",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "df['x'] = df['ingredients'].apply(lambda ingredients: preprocess(ingredients))\ntest_df['x'] = test_df['ingredients'].apply(lambda ingredients: preprocess(ingredients))",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "bfc87d5acd0d71b38b0ab240dfa7d35f2b173d83"
      },
      "cell_type": "markdown",
      "source": "** Creating list of unique words in dataset and then transforming it to list of unique nouns. **"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "b0545c0f0378f81801aa09b4f7272d10ef2ca722",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "ingredients = []\nfor rec in df[\"x\"].values:\n    for el in rec.split():\n        if len(el) > 2:\n            if el not in ingredients:        \n                ingredients.append(el)\n\nis_noun = lambda pos: pos[:2] == 'NN'\n\nn = []              \nfor ingredient in ingredients:\n    tokenized = nltk.word_tokenize(ingredient)\n    tagged = nltk.pos_tag(tokenized)\n    word = tagged[0][0]\n    pos = tagged[0][1]\n    if is_noun(pos) and len(word) > 2:\n        n.append(word)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "441a7e1fe0e31b1983d03345a0f23c8062051d36"
      },
      "cell_type": "markdown",
      "source": "** Transforming every list of ingredients in every recipe to set of words that are present in unique nouns list**"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "9df962c468e73c1b8190b18d83047f6fa586a1c6",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#train\nnew_array = []\nfor rec in df[\"x\"].values:\n    coded_ingredients = []\n    for el in rec.split():\n        if el in n:\n            coded_ingredients.append(el)\n    new_array.append(' '.join(coded_ingredients))\n    \ndf[\"nouns\"] = pd.Series((new_array), index=df.index)\n\n\n#test\nnew_array = []\nfor rec in test_df[\"x\"].values:\n    coded_ingredients = []\n    for el in rec.split():\n        if el in n:\n            coded_ingredients.append(el)\n    new_array.append(' '.join(coded_ingredients))\n    \ntest_df[\"nouns\"] = pd.Series((new_array), index=test_df.index)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "6bd17979149115b174667de36a3c42ae298c3302"
      },
      "cell_type": "markdown",
      "source": "** Encoding labels in the dataset to numerical representation for the model. **"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2350bf50da671036ef4b817a5dc324390629be53",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "le = LabelEncoder()\nle.fit_transform(df[\"cuisine\"].values)\ncuisines = dict(zip(le.classes_, le.transform(le.classes_)))\n\ny = le.transform(df['cuisine'].values)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "dd5fcdf38aca81e826105e2c5efcdefc8e655f6b"
      },
      "cell_type": "markdown",
      "source": "** Transforming list of ingredients to vectors that can be feed to the model **"
    },
    {
      "metadata": {
        "_uuid": "f13e9c9ac859a1601de9b7f1c5a48dcf1bf662ee"
      },
      "cell_type": "markdown",
      "source": "Firstly I've tried doing it myself but doing it using ** TfidVectorizer** reduced learning time a lot."
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "37887880c5decf5cb7c8873444651d83b57b2ca9",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "cvectorizer = make_pipeline(\n    TfidfVectorizer(sublinear_tf=True),\n    FunctionTransformer(lambda x: x.astype('float16'), validate=False)\n)\n\nX = vectorizer.fit_transform(df['nouns'].values)\n\nX_test = vectorizer.transform(test_df['nouns'].values)\n",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3ab9c0bf6ddfa31f2ed77cd2b2469d2cc728dc73",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "#environment issues \n%env JOBLIB_TEMP_FOLDER=/tmp",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "cc035e25e9f7c56942e1a240e82808edc6f467a4"
      },
      "cell_type": "markdown",
      "source": "** Used model is OneVsRestClassifier with Support Vector Machine classifier as estimator. **"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "2ace1ab6e66fc562a8738d5441c6dcc3825b37d6",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "\nestimator = SVC( C=50, \n                 kernel='rbf',\n                 gamma=1.4,\n                 coef0=1,\n                 shrinking=True,\n                 tol=0.001, \n                 max_iter=-1 )\nmodel= OneVsRestClassifier(estimator, n_jobs=4)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b0cb04098c7e1ee68098bdc06515abcdccaa2ae9"
      },
      "cell_type": "markdown",
      "source": "** Training the model **"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "919d56bfebe84e0bc01d21540b54bfd4197acd9b",
        "scrolled": true,
        "collapsed": true
      },
      "cell_type": "code",
      "source": "model.fit(X, y)",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "fc620b704e034b4cfe8ee4ff17b4af2818718b50"
      },
      "cell_type": "markdown",
      "source": "** Predicting labels for submission **"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "3105cdcec60de96487c600785c9db62a7b01f279",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "prediction = model.predict(X_test)\nprediction = le.inverse_transform(prediction)\nprediction = pd.Series(prediction, name='cuisine')",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "_uuid": "b076f25520b4e33e31c4d84a5eb21914cf86038c"
      },
      "cell_type": "markdown",
      "source": "** Saving submission csv **"
    },
    {
      "metadata": {
        "trusted": true,
        "_uuid": "935b1d39a05bfbbdaac7e76db2bd8c57e6cb7b42",
        "collapsed": true
      },
      "cell_type": "code",
      "source": "submission = pd.concat([test_df.id, prediction], axis = 1)\nsubmission.to_csv(\"SVCSubmission_2.csv\", index = False)",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.4",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}